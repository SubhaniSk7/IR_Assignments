{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some .sav files are from 1st question. So, First run First.ipynb and run this file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import os,re,math,glob\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize,RegexpTokenizer,TweetTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import pandas as pd\n",
    "import re as regex\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.externals import joblib\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from my previous assignment\n",
    "def contract(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def regTokenize(text):\n",
    "    tok=RegexpTokenizer('[A-Za-z0-9]*[.]?\\w+')\n",
    "    return tok.tokenize(text) \n",
    "\n",
    "def lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "def lemma(words):\n",
    "    for i in range(0,len(words)):\n",
    "        words[i]=WordNetLemmatizer().lemmatize(words[i])\n",
    "    return words\n",
    "\n",
    "def stemming(words):\n",
    "    porter_stemmer=PorterStemmer()\n",
    "    for i in range(0,len(words)):\n",
    "        words[i]=porter_stemmer.stem(words[i])\n",
    "    return words\n",
    "\n",
    "def tweet(words):\n",
    "    tok=TweetTokenizer()\n",
    "    return tok.tokenize(words)\n",
    "\n",
    "def comma(text):\n",
    "    text = \"\".join(c for c in text if c not in ('!','.',':',',','\"','?','(',')'))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading .sav required files(which are saved in 1st question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stories/100west.txt', 'Going 100 West by 53 North by Jim Prentice (1990)', 3101] \n",
      "\n",
      "stories/100west.txt ['go', '100', 'west', 'by', '53', 'north', 'by', 'jim', 'prentic', '(', '1990', ')'] \n",
      "\n",
      "cackl [13, ['stories/100west.txt', 'stories/assorted.txt', 'stories/bookem.1', 'stories/breaks3.asc', 'stories/candle.hum', 'stories/chik', 'stories/cybersla.txt', 'stories/eyeargon.hum', 'stories/foxngrap.txt', 'stories/fred.txt', 'stories/paink-ws.txt', 'stories/piracy.sto', 'stories/rocket.sf']]\n"
     ]
    }
   ],
   "source": [
    "document_ids=joblib.load('document_ids.sav')\n",
    "metadata=joblib.load('metadata.sav')\n",
    "title_dictionary=joblib.load('title_dictionary.sav')\n",
    "body_dictionary=joblib.load('body_dictionary.sav')\n",
    "for i in metadata:\n",
    "    print(i,'\\n')\n",
    "    break\n",
    "for key,value in title_dictionary.items():\n",
    "    print(key,value,'\\n')\n",
    "    break\n",
    "for key,value in body_dictionary.items():\n",
    "    print(key, value)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting dictionary terms from body_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34830\n"
     ]
    }
   ],
   "source": [
    "words=body_dictionary.keys()\n",
    "print(len(words))\n",
    "words=list(words)\n",
    "# print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDocLength(docId):\n",
    "    for i in metadata:\n",
    "        if(i[0]==docId):\n",
    "            return i[2]\n",
    "\n",
    "def getWordFreqInBodyDoc(docId,word):\n",
    "    f=open(docId,'r+',errors='ignore')\n",
    "    data=f.read()\n",
    "    data=lowercase(data)\n",
    "    data=contract(data)\n",
    "    data=comma(data)\n",
    "#     data=tweet(data)\n",
    "    data=regTokenize(data)\n",
    "    data=lemma(data)\n",
    "    data=stemming(data)\n",
    "    \n",
    "    freq=data.count(word)\n",
    "    return freq\n",
    "\n",
    "def getWordFreqinTitle(docId, word):\n",
    "    return title_dictionary.get(docId).count(word)\n",
    "\n",
    "def getQPosts(term):\n",
    "    return body_dictionary.get(term)[1]\n",
    "\n",
    "def getDocWords(docId):\n",
    "    f=open(docId,'r+',errors='ignore')\n",
    "    data=f.read()\n",
    "    data=lowercase(data)\n",
    "    data=contract(data)\n",
    "    data=comma(data)\n",
    "    data=regTokenize(data)\n",
    "    data=lemma(data)\n",
    "    data=stemming(data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def getTitleWords(docId):\n",
    "    return title_dictionary.get(docId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construction vector space model based on tf-idf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stories/100west.txt\n",
      "stories/13chil.txt\n",
      "stories/14.lws\n",
      "stories/16.lws\n",
      "stories/17.lws\n",
      "stories/18.lws\n",
      "stories/19.lws\n",
      "stories/20.lws\n",
      "stories/3gables.txt\n",
      "stories/3lpigs.txt\n",
      "stories/3sonnets.vrs\n",
      "stories/3student.txt\n",
      "stories/3wishes.txt\n",
      "stories/4moons.txt\n",
      "stories/5orange.txt\n",
      "stories/6ablemen.txt\n",
      "stories/6napolen.txt\n",
      "stories/7oldsamr.txt\n",
      "stories/7voysinb.txt\n",
      "stories/ab40thv.txt\n",
      "stories/abbey.txt\n",
      "stories/abyss.txt\n",
      "stories/adler.txt\n",
      "stories/adv_alad.txt\n",
      "stories/advsayed.txt\n",
      "stories/advtthum.txt\n",
      "stories/aesop11.txt\n",
      "stories/aesopa10.txt\n",
      "stories/aircon.txt\n",
      "stories/aisle.six\n",
      "stories/aislesix.txt\n",
      "stories/alad10.txt\n",
      "stories/alissadl.txt\n",
      "stories/altside.hum\n",
      "stories/aluminum.hum\n",
      "stories/aminegg.txt\n",
      "stories/angelfur.hum\n",
      "stories/angry_ca.txt\n",
      "stories/antcrick.txt\n",
      "stories/aquith.txt\n",
      "stories/arcadia.sty\n",
      "stories/archive\n",
      "stories/arctic.txt\n",
      "stories/asop\n",
      "stories/assorted.txt\n",
      "stories/bagel.man\n",
      "stories/bagelman.txt\n",
      "stories/batlslau.txt\n",
      "stories/beast.asc\n",
      "stories/beautbst.txt\n",
      "stories/beggars.txt\n",
      "stories/bern\n",
      "stories/berternie.txt\n",
      "stories/bestwish\n",
      "stories/beyond.hum\n",
      "stories/bgb.txt\n",
      "stories/bgcspoof.txt\n",
      "stories/bigred.hum\n",
      "stories/bishop00.txt\n",
      "stories/blabnove.hum\n",
      "stories/blabnove.txt\n",
      "stories/blackp.txt\n",
      "stories/blackrdr\n",
      "stories/blak\n",
      "stories/blasters.fic\n",
      "stories/blh.txt\n",
      "stories/blind.txt\n",
      "stories/blossom.pom\n",
      "stories/blue\n",
      "stories/bluebrd.txt\n",
      "stories/bookem.1\n",
      "stories/bookem2\n",
      "stories/bookem3\n",
      "stories/brain.damage\n",
      "stories/bram\n",
      "stories/bran\n",
      "stories/breaks1.asc\n",
      "stories/breaks2.asc\n",
      "stories/breaks3.asc\n",
      "stories/bruce-p.txt\n",
      "stories/buggy.txt\n",
      "stories/buldetal.txt\n",
      "stories/buldream.txt\n",
      "stories/bulfelis.txt\n",
      "stories/bulhuntr.txt\n",
      "stories/bulironb.txt\n",
      "stories/bullove.txt\n",
      "stories/bulmrx.txt\n",
      "stories/bulnland.txt\n",
      "stories/bulnoopt.txt\n",
      "stories/bulolli1.txt\n",
      "stories/bulolli2.txt\n",
      "stories/bulphrek.txt\n",
      "stories/bulprint.txt\n",
      "stories/bulwer.lytton\n",
      "stories/bulzork1.txt\n",
      "stories/bumm\n",
      "stories/bureau.txt\n",
      "stories/burintrv.66\n",
      "stories/burintrv.78\n",
      "stories/burintrv.92\n",
      "stories/burltrs\n",
      "stories/burn\n",
      "stories/cabin.txt\n",
      "stories/cameloto.hum\n",
      "stories/campfire.txt\n",
      "stories/candle.hum\n",
      "stories/cardcnt.txt\n",
      "stories/ccm.txt\n",
      "stories/charlie.txt\n",
      "stories/chik\n",
      "stories/clevdonk.txt\n",
      "stories/clon\n",
      "stories/cmoutmou.txt\n",
      "stories/comp\n",
      "stories/confilct.fun\n",
      "stories/consumdr.hum\n",
      "stories/contrad1.hum\n",
      "stories/cooldark.sto\n",
      "stories/cooldark.txt\n",
      "stories/corcor.hum\n",
      "stories/cow.exploder\n",
      "stories/crabhern.txt\n",
      "stories/crazy.hum\n",
      "stories/cum\n",
      "stories/curious.george\n",
      "stories/cybersla.txt\n",
      "stories/dakota.txt\n",
      "stories/dan\n",
      "stories/darkness.txt\n",
      "stories/day.in.mcdonald\n",
      "stories/deal\n",
      "stories/deathmrs.d\n",
      "stories/deer.txt\n",
      "stories/descent.poe\n",
      "stories/diaryflf.txt\n",
      "stories/dicegame.txt\n",
      "stories/dicksong.txt\n",
      "stories/disco.be.fun\n",
      "stories/discocanbefun.txt\n",
      "stories/domain.poe\n",
      "stories/dopedenn.txt\n",
      "stories/dskool.txt\n",
      "stories/dtruck.txt\n",
      "stories/dwar\n",
      "stories/elite.app\n",
      "stories/elveshoe.txt\n",
      "stories/emperor3.txt\n",
      "stories/empnclot.txt\n",
      "stories/empsjowk.txt\n",
      "stories/empty.txt\n",
      "stories/enc\n",
      "stories/encamp01.txt\n",
      "stories/enchdup.hum\n",
      "stories/enginer.txt\n",
      "stories/enya_trn.txt\n",
      "stories/excerpt.hum\n",
      "stories/excerpt.txt\n",
      "stories/eyeargon.hum\n",
      "stories/ezoff\n",
      "stories/fable.txt\n",
      "stories/fantas.hum\n",
      "stories/fantasy.hum\n",
      "stories/fantasy.txt\n",
      "stories/fea1\n",
      "stories/fea2\n",
      "stories/fea3\n",
      "stories/fear.hum\n",
      "stories/fearmnky\n",
      "stories/fgoose.txt\n",
      "stories/fic1\n",
      "stories/fic2\n",
      "stories/fic3\n",
      "stories/fic4\n",
      "stories/fic5\n",
      "stories/fic7\n",
      "stories/fish.txt\n",
      "stories/fleas.txt\n",
      "stories/flktrp.txt\n",
      "stories/floc\n",
      "stories/floobs.txt\n",
      "stories/flute.txt\n",
      "stories/flytrunk.txt\n",
      "stories/forgotte\n",
      "stories/fourth.fic\n",
      "stories/fowl.death\n",
      "stories/foxncrow.txt\n",
      "stories/foxngrap.txt\n",
      "stories/foxnstrk.txt\n",
      "stories/fran\n",
      "stories/fred.txt\n",
      "stories/freeman.fil\n",
      "stories/friend.s\n",
      "stories/friends.txt\n",
      "stories/frogp.txt\n",
      "stories/frum\n",
      "stories/game.txt\n",
      "stories/gatherng.txt\n",
      "stories/gay\n",
      "stories/gemdra.txt\n",
      "stories/ghost\n",
      "stories/girl\n",
      "stories/girlclub.txt\n",
      "stories/glimpse1.txt\n",
      "stories/gloves.txt\n",
      "stories/gold3ber.txt\n",
      "stories/goldbug.poe\n",
      "stories/goldenp.txt\n",
      "stories/goldfish.txt\n",
      "stories/goldgoos.txt\n",
      "stories/grav\n",
      "stories/graymare.txt\n",
      "stories/greatlrn.leg\n",
      "stories/greedog.txt\n",
      "stories/gulliver.txt\n",
      "stories/hansgrtl.txt\n",
      "stories/hareleph.txt\n",
      "stories/hareporc.txt\n",
      "stories/haretort.txt\n",
      "stories/healer.txt\n",
      "stories/hell4.txt\n",
      "stories/hellmach.txt\n",
      "stories/helmfuse.txt\n",
      "stories/hils\n",
      "stories/history5.txt\n",
      "stories/hitch2.txt\n",
      "stories/hitch3.txt\n",
      "stories/hole2nar.txt\n",
      "stories/holmesbk.txt\n",
      "stories/home.fil\n",
      "stories/hop-frog.poe\n",
      "stories/horsdonk.txt\n",
      "stories/horswolf.txt\n",
      "stories/hotline1.txt\n",
      "stories/hotline3.txt\n",
      "stories/hotline4.txt\n",
      "stories/hound-b.txt\n",
      "stories/how.ernie.bert\n",
      "stories/idi.hum\n",
      "stories/igiv\n",
      "stories/imagin.hum\n",
      "stories/immortal\n",
      "stories/immorti.hum\n",
      "stories/imonly17.txt\n",
      "stories/inter\n",
      "stories/island.poe\n",
      "stories/jackbstl.txt\n",
      "stories/jackmac.fic\n",
      "stories/jaynejob.asc\n",
      "stories/jerichms.hum\n",
      "stories/jim.asc\n",
      "stories/keeping.insanit\n",
      "stories/keepmodu.txt\n",
      "stories/kharian.txt\n",
      "stories/kneeslapper\n",
      "stories/kneeslapper.txt\n",
      "stories/knuckle.txt\n",
      "stories/korea.s\n",
      "stories/kzap.txt\n",
      "stories/ladylust.hum\n",
      "stories/lament.txt\n",
      "stories/lgoldbrd.txt\n",
      "stories/life.txt\n",
      "stories/lil\n",
      "stories/lionbird\n",
      "stories/lionmane.txt\n",
      "stories/lionmosq.txt\n",
      "stories/lionwar.txt\n",
      "stories/lmermaid.txt\n",
      "stories/lmtchgrl.txt\n",
      "stories/long1-3.txt\n",
      "stories/lpeargrl.txt\n",
      "stories/lrrhood.txt\n",
      "stories/ltp\n",
      "stories/luf\n",
      "stories/lure.txt\n",
      "stories/mario.txt\n",
      "stories/mattress.txt\n",
      "stories/mazarin.txt\n",
      "stories/mcdonaldl.txt\n",
      "stories/melissa.txt\n",
      "stories/mike.txt\n",
      "stories/mindprob.txt\n",
      "stories/mindwar\n",
      "stories/missing.txt\n",
      "stories/modemhippy.txt\n",
      "stories/monkking.txt\n",
      "stories/monksol.txt\n",
      "stories/mouslion.txt\n",
      "stories/mtinder.txt\n",
      "stories/musgrave.txt\n",
      "stories/musibrem.txt\n",
      "stories/mydream.txt\n",
      "stories/myeyes\n",
      "stories/narciss.txt\n",
      "stories/nigel.1\n",
      "stories/nigel.10\n",
      "stories/nigel.2\n",
      "stories/nigel.3\n",
      "stories/nigel.4\n",
      "stories/nigel.5\n",
      "stories/nigel.6\n",
      "stories/nigel.7\n",
      "stories/nihgel_8.9\n",
      "stories/nitepeek.sto\n",
      "stories/non2\n",
      "stories/non3\n",
      "stories/non4\n",
      "stories/obstgoat.txt\n",
      "stories/omarsheh.txt\n",
      "stories/outcast.dos\n",
      "stories/oxfrog.txt\n",
      "stories/paink-ws.txt\n",
      "stories/panama.txt\n",
      "stories/parotsha.txt\n",
      "stories/partya.txt\n",
      "stories/paul_har.sto\n",
      "stories/peace.fun\n",
      "stories/pepdegener.txt\n",
      "stories/pepsi.degenerat\n",
      "stories/perf\n",
      "stories/pinocch.txt\n",
      "stories/piracy.sto\n",
      "stories/plescopm.txt\n",
      "stories/poem-1.txt\n",
      "stories/poem-2.txt\n",
      "stories/poem-4.txt\n",
      "stories/poplstrm.txt\n",
      "stories/pphamlin.txt\n",
      "stories/pregn.txt\n",
      "stories/prince.art\n",
      "stories/progx\n",
      "stories/psf.txt\n",
      "stories/psi\n",
      "stories/psyc\n",
      "stories/pussboot.txt\n",
      "stories/qcarroll\n",
      "stories/quarter.c1\n",
      "stories/quarter.c10\n",
      "stories/quarter.c11\n",
      "stories/quarter.c12\n",
      "stories/quarter.c13\n",
      "stories/quarter.c14\n",
      "stories/quarter.c15\n",
      "stories/quarter.c16\n",
      "stories/quarter.c17\n",
      "stories/quarter.c18\n",
      "stories/quarter.c19\n",
      "stories/quarter.c2\n",
      "stories/quarter.c3\n",
      "stories/quarter.c4\n",
      "stories/quarter.c5\n",
      "stories/quarter.c6\n",
      "stories/quarter.c7\n",
      "stories/quarter.c8\n",
      "stories/quarter.c9\n",
      "stories/quest\n",
      "stories/quickfix\n",
      "stories/quot\n",
      "stories/radar_ra.txt\n",
      "stories/rainda.txt\n",
      "stories/reality.txt\n",
      "stories/reap\n",
      "stories/redragon.txt\n",
      "stories/retrib.txt\n",
      "stories/rid.txt\n",
      "stories/robotech\n",
      "stories/rock\n",
      "stories/rocket.sf\n",
      "stories/roger1.txt\n",
      "stories/running.txt\n",
      "stories/s&m_plot\n",
      "stories/s&m_that\n",
      "stories/safe\n",
      "stories/sanpedr2.txt\n",
      "stories/shoscomb.txt\n",
      "stories/shrdfarm.txt\n",
      "stories/shulk.txt\n",
      "stories/sick-kid.txt\n",
      "stories/sight.txt\n",
      "stories/silverb.txt\n",
      "stories/sis\n",
      "stories/sleprncs.txt\n",
      "stories/snow.txt\n",
      "stories/snowmaid.txt\n",
      "stories/snowqn1.txt\n",
      "stories/social.vikings\n",
      "stories/socialvikings.txt\n",
      "stories/solitary.txt\n",
      "stories/space.txt\n",
      "stories/spam.key\n",
      "stories/spectacl.poe\n",
      "stories/spider.txt\n",
      "stories/spiders.txt\n",
      "stories/sqzply.txt\n",
      "stories/sre-dark.txt\n",
      "stories/stainles.ana\n",
      "stories/stairdre.txt\n",
      "stories/startrek.txt\n",
      "stories/stsgreek\n",
      "stories/sucker.txt\n",
      "stories/sunday.txt\n",
      "stories/superg1\n",
      "stories/szechuan\n",
      "stories/t_zone.jok\n",
      "stories/tailbear.txt\n",
      "stories/tao3.dos\n",
      "stories/taxnovel.txt\n",
      "stories/tcoa.txt\n",
      "stories/tctac.txt\n",
      "stories/tearglas.txt\n",
      "stories/telefone.txt\n",
      "stories/terrorbears.txt\n",
      "stories/testpilo.hum\n",
      "stories/textfile.primer\n",
      "stories/thanksg\n",
      "stories/the-tree.txt\n",
      "stories/thewave\n",
      "stories/timem.hac\n",
      "stories/times.fic\n",
      "stories/timetrav.txt\n",
      "stories/tin\n",
      "stories/tinsoldr.txt\n",
      "stories/toilet.s\n",
      "stories/traitor.txt\n",
      "stories/tree.txt\n",
      "stories/tuc_mees\n",
      "stories/uglyduck.txt\n",
      "stories/unluckwr.txt\n",
      "stories/vaincrow.txt\n",
      "stories/vainsong.txt\n",
      "stories/valen\n",
      "stories/vampword.txt\n",
      "stories/vday.hum\n",
      "stories/veiledl.txt\n",
      "stories/vgilante.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stories/wall.art\n",
      "stories/wanderer.fun\n",
      "stories/weaver.txt\n",
      "stories/weeprncs.txt\n",
      "stories/whgdsreg.reg\n",
      "stories/wisteria.txt\n",
      "stories/withdraw.cyb\n",
      "stories/wlgirl.txt\n",
      "stories/wolf7kid.txt\n",
      "stories/wolfcran.txt\n",
      "stories/wolflamb.txt\n",
      "stories/wombat.und\n",
      "stories/write\n",
      "stories/wrt\n",
      "stories/yukon.txt\n",
      "stories/zombies.txt\n",
      "stories/SRE/sre01.txt\n",
      "stories/SRE/sre02.txt\n",
      "stories/SRE/sre03.txt\n",
      "stories/SRE/sre04.txt\n",
      "stories/SRE/sre05.txt\n",
      "stories/SRE/sre06.txt\n",
      "stories/SRE/sre07.txt\n",
      "stories/SRE/sre08.txt\n",
      "stories/SRE/sre09.txt\n",
      "stories/SRE/sre10.txt\n",
      "stories/SRE/sre_feqh.txt\n",
      "stories/SRE/sre_finl.txt\n",
      "stories/SRE/sre_sei.txt\n",
      "stories/SRE/sretrade.txt\n",
      "stories/SRE/srex.txt\n"
     ]
    }
   ],
   "source": [
    "vsm=[]\n",
    "\n",
    "title_weight=0.6\n",
    "body_weight=0.4\n",
    "n=len(document_ids)\n",
    "\n",
    "for i in document_ids:\n",
    "    print(i)\n",
    "    \n",
    "    d_tf_idf=[]\n",
    "    total=0\n",
    "    \n",
    "    doc_words=getDocWords(i)\n",
    "    title_words=getTitleWords(i)\n",
    "    for w in words:\n",
    "#         print(w)\n",
    "        \n",
    "#         bodyFreq=getWordFreqInBodyDoc(i,w)\n",
    "        bodyFreq=doc_words.count(w)\n",
    "#         titleFreq=getWordFreqinTitle(i,w)\n",
    "        titleFreq=title_words.count(w)\n",
    "        \n",
    "        if(bodyFreq>0 and titleFreq>0):\n",
    "            weight=1\n",
    "        elif(bodyFreq>0 and titleFreq==0):\n",
    "            weight=0.4\n",
    "        else:\n",
    "            weight=0.6\n",
    "        \n",
    "        freq=bodyFreq\n",
    "        tf=freq/getDocLength(i)\n",
    "        \n",
    "        inner=n/body_dictionary.get(j)[0]\n",
    "        idf=math.log(inner)\n",
    "        \n",
    "        tf_idf=tf*idf*weight\n",
    "        \n",
    "        d_tf_idf.append(tf_idf)\n",
    "    vsm.append(d_tf_idf)   \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting dictionary to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=list(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving(dumping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vsm.sav']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vsm_fname='vsm.sav'\n",
    "joblib.dump(vsm,vsm_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pre-processing for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing_test(term):\n",
    "    term=lowercase(term)\n",
    "    term=contract(term)\n",
    "    term=comma(term)\n",
    "    term=regTokenize(term)\n",
    "    term=lemma(term)\n",
    "    term=stemming(term)\n",
    "    return term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter query:This is Information\n",
      "enter k:7\n",
      "This is Information   7\n",
      "['thi', 'is', 'inform']\n"
     ]
    }
   ],
   "source": [
    "query=input('enter query:')\n",
    "k=int(input('enter k:'))\n",
    "print(query,' ', k)\n",
    "q_terms=pre_processing_test(query)\n",
    "print(q_terms)\n",
    "\n",
    "q_posts=[]\n",
    "for i in q_terms:\n",
    "    if(i in body_dictionary.keys()):\n",
    "        posts=getQPosts(i)\n",
    "    else:\n",
    "        print(i,' not in dictionary.')\n",
    "        posts=[]\n",
    "    q_posts.append(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### constructing query terms vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_vector=[0 for i in range(len(words))]\n",
    "\n",
    "# for w in range(len(words)):\n",
    "#     word=words[w]\n",
    "#     if(word in q_terms):\n",
    "#         tf=q_terms.count(word)\n",
    "#     else:\n",
    "#         tf=0\n",
    "#     q_vector[w]=tf\n",
    "\n",
    "def getQVector(q_terms):\n",
    "    q_vsm=[0 for i in range(len(words))]\n",
    "    for w in range(len(words)):\n",
    "        word=words[w]\n",
    "        if(word in q_terms):\n",
    "            tf=q_terms.count(word)\n",
    "        else:\n",
    "            tf=0\n",
    "        q_vsm[w]=tf\n",
    "    return q_vsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_vector=getQVector(q_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    }
   ],
   "source": [
    "total_postings=set.intersection(*map(set,q_posts))\n",
    "total_postings=list(total_postings)\n",
    "print(len(total_postings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculating cosine similarity with documents and storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stories/kzap.txt - 258\n",
      "stories/elite.app - 145\n",
      "stories/6napolen.txt - 16\n",
      "stories/floc - 179\n",
      "stories/breaks3.asc - 78\n",
      "stories/whgdsreg.reg - 440\n",
      "stories/mindprob.txt - 282\n",
      "stories/bulzork1.txt - 95\n",
      "stories/hound-b.txt - 236\n",
      "stories/robotech - 366\n",
      "stories/taxnovel.txt - 407\n",
      "stories/hitch2.txt - 225\n",
      "stories/kharian.txt - 253\n",
      "stories/jaynejob.asc - 248\n",
      "stories/bulphrek.txt - 92\n",
      "stories/SRE/sre10.txt - 461\n",
      "stories/SRE/srex.txt - 466\n",
      "stories/cybersla.txt - 126\n",
      "stories/cardcnt.txt - 107\n",
      "stories/nigel.10 - 296\n",
      "stories/friends.txt - 193\n",
      "stories/running.txt - 370\n",
      "stories/hitch3.txt - 226\n",
      "stories/fic2 - 171\n",
      "stories/psi - 333\n",
      "stories/jackmac.fic - 247\n",
      "stories/idi.hum - 238\n",
      "stories/cooldark.txt - 119\n",
      "stories/SRE/sre_sei.txt - 464\n",
      "stories/healer.txt - 219\n",
      "stories/fred.txt - 190\n",
      "stories/bishop00.txt - 58\n",
      "stories/keepmodu.txt - 252\n",
      "stories/arctic.txt - 42\n",
      "stories/quarter.c2 - 348\n",
      "stories/chik - 110\n",
      "stories/radar_ra.txt - 359\n",
      "stories/abbey.txt - 20\n",
      "stories/sre-dark.txt - 395\n",
      "stories/forgotte - 183\n",
      "stories/panama.txt - 313\n",
      "stories/blue - 68\n",
      "stories/arcadia.sty - 40\n",
      "stories/spectacl.poe - 391\n",
      "stories/solitary.txt - 388\n",
      "stories/aesop11.txt - 26\n",
      "stories/shoscomb.txt - 375\n",
      "stories/16.lws - 3\n",
      "stories/bulprint.txt - 93\n",
      "stories/clon - 112\n",
      "stories/SRE/sre08.txt - 459\n",
      "stories/fantasy.txt - 163\n",
      "stories/enya_trn.txt - 155\n",
      "stories/sick-kid.txt - 378\n",
      "stories/SRE/sre_finl.txt - 463\n",
      "stories/quest - 356\n",
      "stories/3student.txt - 11\n",
      "stories/beggars.txt - 50\n",
      "stories/outcast.dos - 310\n",
      "stories/rocket.sf - 368\n",
      "stories/goldenp.txt - 207\n",
      "stories/hellmach.txt - 221\n",
      "stories/campfire.txt - 105\n",
      "stories/beast.asc - 48\n",
      "stories/quarter.c3 - 349\n",
      "stories/tin - 421\n",
      "stories/SRE/sre01.txt - 452\n",
      "stories/sanpedr2.txt - 374\n",
      "stories/missing.txt - 284\n",
      "stories/fantasy.hum - 162\n",
      "stories/cooldark.sto - 118\n",
      "stories/blabnove.hum - 59\n",
      "stories/gulliver.txt - 214\n",
      "stories/charlie.txt - 109\n",
      "stories/wisteria.txt - 441\n",
      "stories/blabnove.txt - 60\n",
      "stories/textfile.primer - 414\n",
      "stories/vgilante.txt - 435\n",
      "stories/goldbug.poe - 206\n",
      "stories/girlclub.txt - 202\n",
      "stories/timem.hac - 418\n",
      "stories/bran - 75\n",
      "stories/crazy.hum - 123\n",
      "stories/history5.txt - 224\n",
      "stories/5orange.txt - 14\n",
      "stories/breaks2.asc - 77\n",
      "stories/breaks1.asc - 76\n",
      "stories/darkness.txt - 129\n",
      "stories/blackp.txt - 61\n",
      "stories/19.lws - 6\n",
      "stories/bruce-p.txt - 79\n",
      "stories/ezoff - 159\n",
      "stories/lure.txt - 275\n",
      "stories/superg1 - 402\n",
      "stories/sqzply.txt - 394\n",
      "stories/bookem.1 - 70\n",
      "stories/fgoose.txt - 169\n",
      "stories/mindwar - 283\n",
      "stories/sucker.txt - 400\n",
      "stories/gatherng.txt - 197\n",
      "stories/dakota.txt - 127\n",
      "stories/ltp - 273\n",
      "stories/batlslau.txt - 47\n",
      "stories/dskool.txt - 142\n",
      "stories/fic1 - 170\n",
      "stories/bureau.txt - 97\n",
      "stories/SRE/sre_feqh.txt - 462\n",
      "stories/bulmrx.txt - 87\n",
      "stories/thewave - 417\n",
      "stories/immorti.hum - 242\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "cosine_values=[]\n",
    "for i in range(len(document_ids)):\n",
    "    cosine_values.append([document_ids[i],0])\n",
    "    \n",
    "for i in total_postings:\n",
    "    index=document_ids.index(i)\n",
    "    print(document_ids[index],'-' ,index)\n",
    "    \n",
    "    dot_prod=np.dot(vsm[index],q_vector)\n",
    "    a=np.linalg.norm(vsm[index],ord=2)\n",
    "    b=np.linalg.norm(q_vector,ord=2)\n",
    "#     print(a,b,(a*b),dot_prod/(a*b))\n",
    "    \n",
    "    numerator=dot_prod\n",
    "    denominator=a*b\n",
    "    sim=numerator/denominator\n",
    "    cosine_values[index]=[document_ids[index],sim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cosine_values[258])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sorting the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "sorted_scores = sorted(cosine_values, key=itemgetter(1),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in sorted_scores:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### printing top K docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stories/dakota.txt', 0.18468984989631773]\n",
      "['stories/keepmodu.txt', 0.18216997471626903]\n",
      "['stories/tin', 0.17004038938928964]\n",
      "['stories/enya_trn.txt', 0.16040993324170455]\n",
      "['stories/blabnove.txt', 0.1453337817731396]\n",
      "['stories/mindprob.txt', 0.13605159725331115]\n",
      "['stories/jaynejob.asc', 0.13046637931827693]\n"
     ]
    }
   ],
   "source": [
    "flag=False\n",
    "if(k<=len(sorted_scores)):\n",
    "    for i in range(k):\n",
    "        print(sorted_scores[i])\n",
    "        flag=True\n",
    "else:\n",
    "    for i in sorted_scores:\n",
    "        print(i)\n",
    "        flag=True\n",
    "\n",
    "if(not flag):\n",
    "    print('No Documents are matched.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
